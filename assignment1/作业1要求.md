### **作业总览**

**目标**：从零开始构建并训练一个标准的 Transformer 语言模型。

**核心任务**：
1.  **实现 Byte-pair encoding (BPE) 分词器**
2.  **实现 Transformer 语言模型**
3.  **实现交叉熵损失函数和 AdamW 优化器**
4.  **实现训练循环，支持模型和优化器状态的保存与加载**

**实验任务**：
1.  在 TinyStories 数据集上训练 BPE 分词器。
2.  使用训练好的分词器将数据集转换为整数 ID 序列。
3.  在 TinyStories 数据集上训练 Transformer 语言模型。
4.  使用训练好的模型生成文本样本并评估困惑度。
5.  在 OpenWebText 数据集上训练模型，并将困惑度提交到排行榜。

---

### **编程限制（非常重要！）**

你必须**从零开始**构建所有组件。**严禁使用**以下 PyTorch 模块和函数，除非特别说明：

*   **禁止使用**：
    *   `torch.nn` 中的绝大部分模块（除了下面允许的）
    *   `torch.nn.functional`
    *   `torch.optim`（除了 `Optimizer` 基类）

*   **允许使用**：
    *   `torch.nn.Parameter`
    *   PyTorch 的容器类，如 `Module`, `ModuleList`, `Sequential` 等。
    *   `torch.optim.Optimizer`（作为你实现优化器的基类）
    *   其他未被明确禁止的 PyTorch 定义。

**核心原则**：保持“从零实现”的精神。如果不确定某个函数是否可用，请在 Slack 上询问。

---

### **AI 工具使用声明**

*   **允许**：向 ChatGPT 等 LLM 咨询**底层编程问题**或**语言模型的高级概念性问题**。
*   **禁止**：直接使用 AI 来解决问题或生成核心代码。
*   **强烈建议**：在 IDE 中**禁用 AI 自动补全功能**（如 GitHub Copilot），以便更深入地理解内容。

---

### **代码结构与提交**

*   **你的代码区**：`cs336_basics/*` 目录，你需要在这里从零开始编写所有代码。
*   **适配器文件**：`adapters.py`。你需要在其中填充函数实现，这些函数将调用你写的代码。此文件不应包含实质性逻辑，只是“粘合”代码。
*   **测试文件**：`test.*.py`。不要编辑这些文件，它们会通过 `adapters.py` 来测试你的实现。
*   **如何提交**：
    *   `writeup.pdf`：回答所有书面问题。
    *   `code.zip`：包含你写的所有代码。
    *   **排行榜提交**：需要向指定的 GitHub 仓库提交 Pull Request。

---

### **数据集**

*   **TinyStories**：一个简单的儿童故事数据集，用于快速开发和调试。
*   **OpenWebText**：一个更大的、来自网络爬取的数据集，用于最终实验和排行榜。

---

### **低资源/降尺度提示**

即使你有强大的 GPU，这些提示也能帮助你更快地迭代：

*   **降尺度策略**：在完整数据集上运行之前，先在**小数据集子集**（如 TinyStories 的验证集）上测试你的代码，以确保其正确性和效率。
*   **在 Apple Silicon 或 CPU 上运行**：作业设计为可以在 Mac M系列芯片（使用 MPS）或 CPU 上运行。对于 TinyStories，可以在合理时间内（几分钟到几十分钟）训练出能生成流畅文本的小模型。
*   **性能分析**：使用 `cProfile` 或 `scalene` 等工具分析代码瓶颈，并重点优化。

---

### **最终需要实现的效果**

1.  **一个功能完整的 BPE 分词器**：能够训练词汇表、对文本进行编码（字符串 -> ID列表）和解码（ID列表 -> 字符串）。
2.  **一个结构正确的 Transformer 语言模型**：包含嵌入层、多层 Pre-norm Transformer 块（内含 RMSNorm, SwiGLU FFN, RoPE, 因果自注意力等）和输出层。
3.  **一套完整的训练工具**：包括交叉熵损失、AdamW 优化器、学习率调度、梯度裁剪、数据加载器和训练循环。
4.  **一个文本生成器**：能够从训练好的模型中生成文本，支持温度调节和 Top-p 采样。
5.  **实验与分析**：在 TinyStories 和 OpenWebText 上成功训练模型，进行超参数调优（如学习率、批大小），完成架构消融实验（如移除 RMSNorm，比较 Pre-norm/Post-norm，比较 SwiGLU/SiLU 等），并生成文本和困惑度报告。
6.  **排行榜提交**：在 OpenWebText 上，在 1.5 小时 H100 计算限制内，尽可能优化模型以取得最低的验证损失。
